{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a75936",
   "metadata": {},
   "source": [
    "# Credit Risk Prediction with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b640cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b8c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages if needed\n",
    "# !pip install shap xgboost lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec95655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: F:\\Datas\\AI_Course\\Soft_Skill\\4 Module\\V02\\New folder\\project_output\n"
     ]
    }
   ],
   "source": [
    "#  USER: set your dataset path here \n",
    "DATA_PATH = Path(r\"F:\\Datas\\AI_Course\\Soft_Skill\\4 Module\\Dataset\\archive\\credit_risk_dataset.csv\")\n",
    "\n",
    "OUT_DIR = Path(\"project_output\")\n",
    "MODELS_DIR = OUT_DIR / \"models\"\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "\n",
    "for p in [OUT_DIR, MODELS_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Output directory:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca76061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (32581, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>D</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>5500</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0    PERSONAL          D      35000          16.02            1   \n",
       "1   EDUCATION          B       1000          11.14            0   \n",
       "2     MEDICAL          C       5500          12.87            1   \n",
       "3     MEDICAL          C      35000          15.23            1   \n",
       "4     MEDICAL          C      35000          14.27            1   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                 0.59                         Y                           3  \n",
       "1                 0.10                         N                           2  \n",
       "2                 0.57                         N                           3  \n",
       "3                 0.53                         N                           2  \n",
       "4                 0.55                         Y                           4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f5cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using target column: loan_status\n",
      "Numeric cols: 7 Categorical cols: 4\n"
     ]
    }
   ],
   "source": [
    "# Detect target column\n",
    "possible_targets = [\"default\",\"is_default\",\"loan_status\",\"target\",\"status\",\"label\",\"default_payment_next_month\"]\n",
    "target_col = None\n",
    "for c in df.columns:\n",
    "    if c.lower() in possible_targets:\n",
    "        target_col = c\n",
    "        break\n",
    "if target_col is None:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print(\"Using target column:\", target_col)\n",
    "\n",
    "y = df[target_col].astype(\"category\").cat.codes\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric cols:\", len(num_cols), \"Categorical cols:\", len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c273bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing pipeline\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edba9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (26064, 11) Test shape: (6517, 11)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c9f1950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: random_forest\n",
      "Saved: project_output\\models\\random_forest.joblib\n",
      "Training: xgboost\n",
      "Saved: project_output\\models\\xgboost.joblib\n",
      "Training: lightgbm\n",
      "[LightGBM] [Info] Number of positive: 5686, number of negative: 20378\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 26064, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218155 -> initscore=-1.276449\n",
      "[LightGBM] [Info] Start training from score -1.276449\n",
      "Saved: project_output\\models\\lightgbm.joblib\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "models = {}\n",
    "\n",
    "# RandomForest baseline\n",
    "models[\"random_forest\"] = Pipeline([\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    models[\"xgboost\"] = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"model\", xgb_clf)\n",
    "    ])\n",
    "except Exception as e:\n",
    "    print(\"XGBoost not available:\", e)\n",
    "\n",
    "# LightGBM\n",
    "try:\n",
    "    lgb_clf = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    )\n",
    "    models[\"lightgbm\"] = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"model\", lgb_clf)\n",
    "    ])\n",
    "except Exception as e:\n",
    "    print(\"LightGBM not available:\", e)\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(\"Training:\", name)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    outp = MODELS_DIR / f\"{name}.joblib\"\n",
    "    joblib.dump(pipe, outp)\n",
    "    print(\"Saved:\", outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23d2124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics: project_output\\random_forest_metrics.json\n",
      "Saved metrics: project_output\\xgboost_metrics.json\n",
      "Saved metrics: project_output\\lightgbm_metrics.json\n",
      "Best model: lightgbm\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and save metrics\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    try:\n",
    "        y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "    except Exception:\n",
    "        y_proba = y_pred\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, y_proba))\n",
    "    }\n",
    "    results[name] = metrics\n",
    "    mfile = OUT_DIR / f\"{name}_metrics.json\"\n",
    "    if mfile.exists():\n",
    "        mfile.unlink()\n",
    "    with open(mfile, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(\"Saved metrics:\", mfile)\n",
    "\n",
    "best_name = max(results.items(), key=lambda kv: kv[1][\"roc_auc\"])[0]\n",
    "best_model = models[best_name]\n",
    "print(\"Best model:\", best_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7de62cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP summary + feature importance\n"
     ]
    }
   ],
   "source": [
    "# SHAP global analysis\n",
    "preproc = best_model.named_steps[\"preproc\"]\n",
    "model_obj = best_model.named_steps[\"model\"]\n",
    "X_test_pre = preproc.transform(X_test)\n",
    "\n",
    "# Feature names for transformed data\n",
    "try:\n",
    "    feat_names = preproc.get_feature_names_out()\n",
    "    feat_names = [str(f) for f in feat_names]\n",
    "except Exception:\n",
    "    feat_names = num_cols + [f\"{c}_encoded\" for c in cat_cols]\n",
    "\n",
    "# SHAP DataFrame\n",
    "try:\n",
    "    X_test_pre_df = pd.DataFrame(X_test_pre, columns=feat_names)\n",
    "except Exception:\n",
    "    X_test_pre_df = pd.DataFrame(X_test_pre)\n",
    "    feat_names = X_test_pre_df.columns.astype(str).tolist()\n",
    "\n",
    "# Explain\n",
    "explainer = shap.TreeExplainer(model_obj)\n",
    "sv_raw = explainer.shap_values(X_test_pre)\n",
    "\n",
    "# pick positive class\n",
    "if isinstance(sv_raw, list):\n",
    "    shap_values = np.array(sv_raw[1]) if len(sv_raw) > 1 else np.array(sv_raw[0])\n",
    "else:\n",
    "    shap_values = np.array(sv_raw)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(8,6))\n",
    "shap.summary_plot(shap_values, X_test_pre_df, feature_names=feat_names, show=False)\n",
    "summary_path = FIG_DIR / \"shap_summary.png\"\n",
    "if summary_path.exists():\n",
    "    summary_path.unlink()\n",
    "plt.savefig(str(summary_path), bbox_inches='tight', dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Feature importance\n",
    "fi_path = OUT_DIR / \"shap_feature_importance.csv\"\n",
    "if fi_path.exists():\n",
    "    fi_path.unlink()\n",
    "mean_abs = np.mean(np.abs(shap_values), axis=0)\n",
    "if len(mean_abs) == len(feat_names):\n",
    "    feat_imp = pd.Series(mean_abs, index=feat_names).sort_values(ascending=False)\n",
    "else:\n",
    "    feat_imp = pd.Series(mean_abs).sort_values(ascending=False)\n",
    "feat_imp.to_csv(fi_path)\n",
    "print(\"Saved SHAP summary + feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356eb426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependence plots for: ['num__loan_percent_income', 'cat__loan_grade', 'num__person_income']\n"
     ]
    }
   ],
   "source": [
    "# Dependence plots for top 3 features\n",
    "try:\n",
    "    top_feats = feat_imp.index[:3].tolist()\n",
    "except Exception:\n",
    "    top_feats = list(range(min(3, X_test_pre.shape[1])))\n",
    "\n",
    "for f in top_feats:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    shap.dependence_plot(f, shap_values, X_test_pre_df, feature_names=feat_names, show=False)\n",
    "    dep_path = FIG_DIR / f\"dependence_{str(f).replace('/','_')}.png\"\n",
    "    if dep_path.exists():\n",
    "        dep_path.unlink()\n",
    "    plt.savefig(str(dep_path), bbox_inches='tight', dpi=200)\n",
    "    plt.close()\n",
    "print(\"Saved dependence plots for:\", top_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e466dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved local explanation: project_output\\figures\\true_positive.png\n",
      "Saved local explanation: project_output\\figures\\true_negative.png\n",
      "Saved local explanation: project_output\\figures\\false_positive.png\n"
     ]
    }
   ],
   "source": [
    "# Local SHAP explanations  always generate true_positive, true_negative, false_positive PNGs\n",
    "\n",
    "y_test_arr = np.array(y_test)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "idx_tp_arr = np.where((y_test_arr == 1) & (y_pred_test == 1))[0]\n",
    "idx_tn_arr = np.where((y_test_arr == 0) & (y_pred_test == 0))[0]\n",
    "idx_fp_arr = np.where((y_test_arr == 0) & (y_pred_test == 1))[0]\n",
    "\n",
    "def pick_index(arr, fallback):\n",
    "    return int(arr[0]) if len(arr) > 0 else int(fallback)\n",
    "\n",
    "fallback_idx = 0  # always valid as long as test set non-empty\n",
    "\n",
    "indices = {\n",
    "    \"true_positive\": pick_index(idx_tp_arr, fallback_idx),\n",
    "    \"true_negative\": pick_index(idx_tn_arr, fallback_idx),\n",
    "    \"false_positive\": pick_index(idx_fp_arr, fallback_idx)\n",
    "}\n",
    "\n",
    "for label, idx in indices.items():\n",
    "    outp = FIG_DIR / f\"{label}.png\"\n",
    "    # Make sure idx is in range\n",
    "    if idx < 0 or idx >= shap_values.shape[0]:\n",
    "        idx = 0\n",
    "    # Simple bar chart explanation (robust)\n",
    "    contrib = pd.Series(\n",
    "        shap_values[idx],\n",
    "        index=feat_names if len(shap_values[idx]) == len(feat_names) else range(len(shap_values[idx]))\n",
    "    )\n",
    "    top = contrib.abs().sort_values(ascending=False).head(10)\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    top.plot.bar(ax=ax)\n",
    "    ax.set_title(f\"Local SHAP explanation: {label}\")\n",
    "    if outp.exists():\n",
    "        outp.unlink()\n",
    "    fig.savefig(str(outp), bbox_inches='tight', dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved local explanation:\", outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0544d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: project_output\\report.md\n"
     ]
    }
   ],
   "source": [
    "# Write full report (overwrite safely)\n",
    "report_path = OUT_DIR / \"report.md\"\n",
    "if report_path.exists():\n",
    "    report_path.unlink()\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Credit Risk Prediction â€” Final Report\\n\\n\")\n",
    "    f.write(\"## Dataset\\n\")\n",
    "    f.write(f\"- Source file: {DATA_PATH}\\n\")\n",
    "    f.write(f\"- Shape: {df.shape}\\n\\n\")\n",
    "    f.write(\"## Preprocessing\\n\")\n",
    "    f.write(\"- Numeric imputation (median) and scaling.\\n\")\n",
    "    f.write(\"- Categorical imputation and ordinal encoding.\\n\\n\")\n",
    "    f.write(\"## Models Trained\\n\")\n",
    "    for nm in results:\n",
    "        f.write(f\"- {nm}: ROC_AUC={results[nm]['roc_auc']:.4f}, F1={results[nm]['f1']:.4f}\\n\")\n",
    "    f.write(f\"\\n**Selected best model:** {best_name}\\n\\n\")\n",
    "    f.write(\"## SHAP\\n\")\n",
    "    f.write(\"- Global SHAP summary plot included.\\n\")\n",
    "    f.write(\"- SHAP dependence plots for top 3 features included.\\n\")\n",
    "    f.write(\"- Local explanations (true_positive, true_negative, false_positive) included.\\n\\n\")\n",
    "    f.write(\"## Interpretation\\n\")\n",
    "    f.write(\"SHAP analysis provides both global and local interpretability to support lending decisions.\\n\\n\")\n",
    "    f.write(\"## Conclusion and Recommendations\\n\")\n",
    "    f.write(\"Use model probabilities and SHAP explanations to create explainable decision workflows for loan approvals.\\n\")\n",
    "print(\"Saved report:\", report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59307b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ZIP: F:\\Datas\\AI_Course\\Soft_Skill\\4 Module\\V02\\New folder\\project_output.zip\n"
     ]
    }
   ],
   "source": [
    "# Create ZIP (overwrite if exists)\n",
    "zip_path = Path(\"project_output.zip\")\n",
    "if zip_path.exists():\n",
    "    zip_path.unlink()\n",
    "shutil.make_archive(\"project_output\", \"zip\", OUT_DIR)\n",
    "print(\"Created ZIP:\", zip_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf26bf-1763-4abb-adca-9539311c5ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c4bcd-d7f7-40a3-8a67-4a1606d07ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75bb72-c7d6-4b82-a55a-36497501fde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c818b-2580-417f-8b75-d07f1f93e867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
